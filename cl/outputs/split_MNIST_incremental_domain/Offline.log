split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
FF mlp
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=False)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=False)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (All): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model:  570402
no learnable params:  570402
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.5880 (0.5880)	0.0997 (0.0997)	0.690 (0.690)	48.44 (48.44)
[100/469]	0.0037 (0.0177)	0.0015 (0.0101)	0.051 (0.194)	97.66 (92.37)
[200/469]	0.0023 (0.0147)	0.0003 (0.0095)	0.066 (0.145)	97.66 (94.50)
[300/469]	0.0034 (0.0136)	0.0003 (0.0093)	0.049 (0.123)	98.44 (95.37)
[400/469]	0.0024 (0.0131)	0.0003 (0.0091)	0.102 (0.109)	96.09 (95.95)
[468/469]	0.0023 (0.0130)	0.0002 (0.0091)	0.067 (0.103)	95.83 (96.22)
 * Train Acc 96.218
 * Val Acc 97.960, Total time 1.00
Epoch:1
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1212 (0.1212)	0.1178 (0.1178)	0.039 (0.039)	98.44 (98.44)
[100/469]	0.0091 (0.0125)	0.0065 (0.0099)	0.011 (0.048)	100.00 (98.37)
[200/469]	0.0264 (0.0124)	0.0239 (0.0094)	0.086 (0.049)	97.66 (98.31)
[300/469]	0.0057 (0.0120)	0.0034 (0.0091)	0.043 (0.050)	98.44 (98.25)
[400/469]	0.0355 (0.0122)	0.0287 (0.0090)	0.023 (0.049)	99.22 (98.30)
[468/469]	0.0031 (0.0120)	0.0010 (0.0089)	0.007 (0.050)	100.00 (98.26)
 * Train Acc 98.260
 * Val Acc 98.130, Total time 1.00
Epoch:2
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1228 (0.1228)	0.1182 (0.1182)	0.026 (0.026)	99.22 (99.22)
[100/469]	0.0224 (0.0126)	0.0201 (0.0100)	0.049 (0.035)	97.66 (98.69)
[200/469]	0.0099 (0.0121)	0.0075 (0.0094)	0.027 (0.034)	99.22 (98.80)
[300/469]	0.0025 (0.0119)	0.0003 (0.0092)	0.008 (0.035)	100.00 (98.77)
[400/469]	0.0067 (0.0120)	0.0025 (0.0091)	0.016 (0.036)	99.22 (98.73)
[468/469]	0.0021 (0.0119)	0.0002 (0.0091)	0.004 (0.036)	100.00 (98.73)
 * Train Acc 98.732
 * Val Acc 98.600, Total time 1.03
Epoch:3
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1898 (0.1898)	0.1863 (0.1863)	0.016 (0.016)	100.00 (100.00)
[100/469]	0.0040 (0.0134)	0.0015 (0.0108)	0.014 (0.025)	100.00 (99.13)
[200/469]	0.0044 (0.0123)	0.0018 (0.0094)	0.015 (0.027)	99.22 (99.08)
[300/469]	0.0081 (0.0120)	0.0057 (0.0092)	0.014 (0.026)	99.22 (99.10)
[400/469]	0.0022 (0.0121)	0.0003 (0.0092)	0.018 (0.026)	99.22 (99.06)
[468/469]	0.0022 (0.0120)	0.0002 (0.0092)	0.011 (0.028)	100.00 (99.02)
 * Train Acc 99.020
 * Val Acc 98.840, Total time 1.09
 * Val Acc 98.840, Total time 1.01
OrderedDict([('All', {'All': 98.84})])
Task All average acc: 98.84
===Summary of experiment repeats: 1 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [98.84  0.    0.    0.    0.    0.    0.    0.    0.    0.  ]
mean: 9.884 std: 29.652000000000005
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
FF mlp
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=False)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=False)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (All): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model:  570402
no learnable params:  570402
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1353 (0.1353)	0.1312 (0.1312)	0.689 (0.689)	50.78 (50.78)
[100/469]	0.0250 (0.0128)	0.0224 (0.0103)	0.088 (0.202)	96.09 (91.53)
[200/469]	0.0153 (0.0121)	0.0128 (0.0094)	0.061 (0.146)	97.66 (94.15)
[300/469]	0.0040 (0.0119)	0.0015 (0.0092)	0.083 (0.122)	97.66 (95.22)
[400/469]	0.0024 (0.0120)	0.0003 (0.0093)	0.032 (0.111)	99.22 (95.78)
[468/469]	0.0023 (0.0119)	0.0002 (0.0093)	0.028 (0.104)	98.96 (96.06)
 * Train Acc 96.060
 * Val Acc 97.890, Total time 1.00
Epoch:1
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1581 (0.1581)	0.1544 (0.1544)	0.050 (0.050)	98.44 (98.44)
[100/469]	0.0225 (0.0135)	0.0154 (0.0101)	0.019 (0.052)	99.22 (98.15)
[200/469]	0.0069 (0.0127)	0.0044 (0.0094)	0.031 (0.050)	99.22 (98.18)
[300/469]	0.0102 (0.0123)	0.0081 (0.0091)	0.033 (0.051)	99.22 (98.19)
[400/469]	0.0031 (0.0120)	0.0007 (0.0090)	0.055 (0.050)	97.66 (98.24)
[468/469]	0.0021 (0.0119)	0.0002 (0.0089)	0.037 (0.049)	98.96 (98.28)
 * Train Acc 98.285
 * Val Acc 98.670, Total time 0.99
Epoch:2
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.2354 (0.2354)	0.2297 (0.2297)	0.027 (0.027)	99.22 (99.22)
[100/469]	0.0037 (0.0143)	0.0014 (0.0114)	0.087 (0.032)	96.88 (98.85)
[200/469]	0.0024 (0.0133)	0.0003 (0.0105)	0.018 (0.036)	100.00 (98.71)
[300/469]	0.0025 (0.0126)	0.0002 (0.0100)	0.056 (0.036)	98.44 (98.73)
[400/469]	0.0268 (0.0123)	0.0244 (0.0098)	0.020 (0.036)	99.22 (98.73)
[468/469]	0.0023 (0.0122)	0.0002 (0.0096)	0.021 (0.036)	98.96 (98.74)
 * Train Acc 98.738
 * Val Acc 98.540, Total time 1.08
Epoch:3
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1093 (0.1093)	0.1058 (0.1058)	0.030 (0.030)	99.22 (99.22)
[100/469]	0.0157 (0.0127)	0.0132 (0.0101)	0.029 (0.029)	99.22 (98.95)
[200/469]	0.0104 (0.0120)	0.0081 (0.0094)	0.039 (0.028)	99.22 (99.02)
[300/469]	0.0044 (0.0120)	0.0021 (0.0093)	0.083 (0.028)	96.88 (99.03)
[400/469]	0.0085 (0.0118)	0.0058 (0.0091)	0.047 (0.028)	97.66 (99.03)
[468/469]	0.0023 (0.0118)	0.0002 (0.0091)	0.043 (0.029)	96.88 (98.99)
 * Train Acc 98.988
 * Val Acc 98.660, Total time 1.01
 * Val Acc 98.660, Total time 0.99
OrderedDict([('All', {'All': 98.66})])
Task All average acc: 98.66
===Summary of experiment repeats: 2 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [98.84 98.66  0.    0.    0.    0.    0.    0.    0.    0.  ]
mean: 19.75 std: 39.50002050632379
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
FF mlp
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=False)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=False)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (All): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model:  570402
no learnable params:  570402
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1701 (0.1701)	0.1658 (0.1658)	0.696 (0.696)	45.31 (45.31)
[100/469]	0.0276 (0.0140)	0.0254 (0.0113)	0.136 (0.195)	95.31 (92.06)
[200/469]	0.0038 (0.0131)	0.0014 (0.0103)	0.094 (0.146)	96.09 (94.20)
[300/469]	0.0308 (0.0125)	0.0284 (0.0099)	0.047 (0.122)	99.22 (95.25)
[400/469]	0.0251 (0.0123)	0.0227 (0.0097)	0.045 (0.108)	98.44 (95.84)
[468/469]	0.0024 (0.0121)	0.0002 (0.0095)	0.123 (0.102)	96.88 (96.11)
 * Train Acc 96.110
 * Val Acc 97.900, Total time 0.99
Epoch:1
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1156 (0.1156)	0.1122 (0.1122)	0.036 (0.036)	99.22 (99.22)
[100/469]	0.0026 (0.0128)	0.0004 (0.0100)	0.053 (0.053)	97.66 (98.23)
[200/469]	0.0050 (0.0124)	0.0021 (0.0094)	0.120 (0.055)	97.66 (98.08)
[300/469]	0.0133 (0.0121)	0.0100 (0.0092)	0.069 (0.053)	96.88 (98.15)
[400/469]	0.0302 (0.0120)	0.0277 (0.0092)	0.072 (0.051)	97.66 (98.24)
[468/469]	0.0162 (0.0120)	0.0140 (0.0091)	0.026 (0.050)	98.96 (98.26)
 * Train Acc 98.258
 * Val Acc 98.580, Total time 1.01
Epoch:2
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1011 (0.1011)	0.0981 (0.0981)	0.048 (0.048)	97.66 (97.66)
[100/469]	0.0123 (0.0125)	0.0100 (0.0100)	0.061 (0.034)	96.88 (98.82)
[200/469]	0.0061 (0.0120)	0.0037 (0.0094)	0.015 (0.036)	99.22 (98.75)
[300/469]	0.0394 (0.0123)	0.0368 (0.0096)	0.037 (0.039)	98.44 (98.65)
[400/469]	0.0029 (0.0120)	0.0003 (0.0093)	0.048 (0.038)	97.66 (98.69)
[468/469]	0.0130 (0.0120)	0.0109 (0.0093)	0.051 (0.037)	98.96 (98.70)
 * Train Acc 98.700
 * Val Acc 98.570, Total time 0.99
Epoch:3
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1563 (0.1563)	0.1494 (0.1494)	0.046 (0.046)	98.44 (98.44)
[100/469]	0.0027 (0.0128)	0.0003 (0.0102)	0.075 (0.030)	96.88 (98.92)
[200/469]	0.0027 (0.0127)	0.0003 (0.0097)	0.044 (0.030)	98.44 (98.92)
[300/469]	0.0022 (0.0122)	0.0003 (0.0094)	0.008 (0.029)	100.00 (98.94)
[400/469]	0.0204 (0.0120)	0.0180 (0.0092)	0.032 (0.029)	98.44 (98.95)
[468/469]	0.0186 (0.0120)	0.0159 (0.0091)	0.030 (0.029)	98.96 (98.92)
 * Train Acc 98.917
 * Val Acc 98.850, Total time 1.09
 * Val Acc 98.850, Total time 1.05
OrderedDict([('All', {'All': 98.85})])
Task All average acc: 98.85
===Summary of experiment repeats: 3 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [98.84 98.66 98.85  0.    0.    0.    0.    0.    0.    0.  ]
mean: 29.635 std: 45.2682354968691
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
FF mlp
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=False)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=False)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (All): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model:  570402
no learnable params:  570402
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1238 (0.1238)	0.1161 (0.1161)	0.699 (0.699)	50.00 (50.00)
[100/469]	0.0051 (0.0124)	0.0022 (0.0098)	0.121 (0.200)	95.31 (91.48)
[200/469]	0.0286 (0.0125)	0.0264 (0.0098)	0.072 (0.149)	96.88 (93.93)
[300/469]	0.0026 (0.0122)	0.0003 (0.0096)	0.032 (0.127)	98.44 (94.95)
[400/469]	0.0051 (0.0126)	0.0026 (0.0096)	0.039 (0.114)	98.44 (95.60)
[468/469]	0.0019 (0.0125)	0.0001 (0.0096)	0.051 (0.106)	98.96 (95.94)
 * Train Acc 95.940
 * Val Acc 97.700, Total time 1.01
Epoch:1
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1316 (0.1316)	0.1278 (0.1278)	0.068 (0.068)	96.88 (96.88)
[100/469]	0.0245 (0.0126)	0.0202 (0.0100)	0.099 (0.053)	97.66 (98.14)
[200/469]	0.0027 (0.0121)	0.0003 (0.0096)	0.028 (0.052)	100.00 (98.19)
[300/469]	0.0025 (0.0118)	0.0003 (0.0092)	0.029 (0.053)	99.22 (98.16)
[400/469]	0.0054 (0.0117)	0.0028 (0.0092)	0.042 (0.051)	99.22 (98.23)
[468/469]	0.0073 (0.0118)	0.0015 (0.0090)	0.044 (0.050)	98.96 (98.28)
 * Train Acc 98.275
 * Val Acc 98.350, Total time 1.07
Epoch:2
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1341 (0.1341)	0.1304 (0.1304)	0.051 (0.051)	97.66 (97.66)
[100/469]	0.0250 (0.0128)	0.0223 (0.0102)	0.064 (0.033)	97.66 (98.84)
[200/469]	0.0022 (0.0123)	0.0003 (0.0096)	0.149 (0.035)	96.09 (98.75)
[300/469]	0.0093 (0.0120)	0.0053 (0.0093)	0.016 (0.035)	100.00 (98.73)
[400/469]	0.0278 (0.0119)	0.0254 (0.0093)	0.025 (0.035)	99.22 (98.75)
[468/469]	0.0033 (0.0118)	0.0011 (0.0092)	0.031 (0.035)	98.96 (98.74)
 * Train Acc 98.738
 * Val Acc 98.810, Total time 1.07
Epoch:3
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1699 (0.1699)	0.1663 (0.1663)	0.013 (0.013)	100.00 (100.00)
[100/469]	0.0025 (0.0128)	0.0003 (0.0102)	0.004 (0.026)	100.00 (99.17)
[200/469]	0.0273 (0.0122)	0.0211 (0.0095)	0.004 (0.025)	100.00 (99.17)
[300/469]	0.0025 (0.0120)	0.0003 (0.0093)	0.034 (0.026)	99.22 (99.10)
[400/469]	0.0075 (0.0118)	0.0003 (0.0092)	0.015 (0.027)	99.22 (99.08)
[468/469]	0.0108 (0.0118)	0.0079 (0.0092)	0.016 (0.028)	100.00 (99.04)
 * Train Acc 99.043
 * Val Acc 98.670, Total time 1.06
 * Val Acc 98.670, Total time 1.00
OrderedDict([('All', {'All': 98.67})])
Task All average acc: 98.67
===Summary of experiment repeats: 4 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [98.84 98.66 98.85 98.67  0.    0.    0.    0.    0.    0.  ]
mean: 39.501999999999995 std: 48.37990549804743
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
FF mlp
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=False)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=False)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (All): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model:  570402
no learnable params:  570402
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1477 (0.1477)	0.1437 (0.1437)	0.697 (0.697)	54.69 (54.69)
[100/469]	0.0022 (0.0136)	0.0003 (0.0109)	0.110 (0.192)	95.31 (92.01)
[200/469]	0.0191 (0.0129)	0.0167 (0.0101)	0.077 (0.142)	96.88 (94.36)
[300/469]	0.0025 (0.0124)	0.0003 (0.0098)	0.084 (0.119)	96.88 (95.36)
[400/469]	0.0026 (0.0122)	0.0003 (0.0096)	0.079 (0.109)	98.44 (95.85)
[468/469]	0.0021 (0.0121)	0.0002 (0.0095)	0.096 (0.102)	96.88 (96.16)
 * Train Acc 96.155
 * Val Acc 98.090, Total time 1.03
Epoch:1
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.2470 (0.2470)	0.2407 (0.2407)	0.075 (0.075)	97.66 (97.66)
[100/469]	0.0025 (0.0139)	0.0003 (0.0110)	0.052 (0.050)	97.66 (98.14)
[200/469]	0.0043 (0.0126)	0.0021 (0.0099)	0.066 (0.050)	97.66 (98.19)
[300/469]	0.0072 (0.0126)	0.0051 (0.0096)	0.175 (0.050)	96.09 (98.24)
[400/469]	0.0202 (0.0123)	0.0178 (0.0094)	0.096 (0.049)	99.22 (98.32)
[468/469]	0.0027 (0.0121)	0.0008 (0.0092)	0.006 (0.048)	100.00 (98.35)
 * Train Acc 98.347
 * Val Acc 98.490, Total time 1.01
Epoch:2
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1382 (0.1382)	0.1342 (0.1342)	0.030 (0.030)	98.44 (98.44)
[100/469]	0.0049 (0.0137)	0.0024 (0.0110)	0.015 (0.031)	99.22 (98.94)
[200/469]	0.0248 (0.0128)	0.0223 (0.0101)	0.069 (0.034)	95.31 (98.81)
[300/469]	0.0024 (0.0126)	0.0003 (0.0100)	0.026 (0.034)	98.44 (98.76)
[400/469]	0.0043 (0.0123)	0.0019 (0.0097)	0.018 (0.035)	100.00 (98.76)
[468/469]	0.0019 (0.0122)	0.0001 (0.0096)	0.013 (0.036)	100.00 (98.70)
 * Train Acc 98.702
 * Val Acc 98.430, Total time 1.02
Epoch:3
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1211 (0.1211)	0.1176 (0.1176)	0.010 (0.010)	100.00 (100.00)
[100/469]	0.0235 (0.0126)	0.0212 (0.0100)	0.034 (0.025)	98.44 (99.09)
[200/469]	0.0231 (0.0125)	0.0207 (0.0096)	0.057 (0.027)	98.44 (99.03)
[300/469]	0.0120 (0.0122)	0.0096 (0.0093)	0.063 (0.027)	96.88 (99.05)
[400/469]	0.0078 (0.0120)	0.0015 (0.0090)	0.019 (0.028)	99.22 (99.01)
[468/469]	0.0211 (0.0121)	0.0189 (0.0091)	0.008 (0.028)	100.00 (99.01)
 * Train Acc 99.013
 * Val Acc 98.780, Total time 0.98
 * Val Acc 98.780, Total time 1.04
OrderedDict([('All', {'All': 98.78})])
Task All average acc: 98.78
===Summary of experiment repeats: 5 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [98.84 98.66 98.85 98.67 98.78  0.    0.    0.    0.    0.  ]
mean: 49.379999999999995 std: 49.38003341432648
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
FF mlp
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=False)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=False)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (All): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model:  570402
no learnable params:  570402
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1113 (0.1113)	0.1071 (0.1071)	0.681 (0.681)	53.12 (53.12)
[100/469]	0.0063 (0.0127)	0.0039 (0.0102)	0.127 (0.195)	93.75 (92.13)
[200/469]	0.0023 (0.0123)	0.0003 (0.0098)	0.066 (0.147)	97.66 (94.27)
[300/469]	0.0126 (0.0125)	0.0099 (0.0099)	0.026 (0.124)	99.22 (95.29)
[400/469]	0.0343 (0.0123)	0.0319 (0.0097)	0.104 (0.110)	97.66 (95.86)
[468/469]	0.0024 (0.0122)	0.0002 (0.0096)	0.068 (0.105)	97.92 (96.09)
 * Train Acc 96.087
 * Val Acc 98.420, Total time 1.01
Epoch:1
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1149 (0.1149)	0.1114 (0.1114)	0.047 (0.047)	99.22 (99.22)
[100/469]	0.0031 (0.0126)	0.0007 (0.0101)	0.078 (0.051)	96.88 (98.18)
[200/469]	0.0041 (0.0127)	0.0020 (0.0095)	0.071 (0.054)	95.31 (98.09)
[300/469]	0.0113 (0.0123)	0.0089 (0.0093)	0.038 (0.050)	99.22 (98.26)
[400/469]	0.0024 (0.0121)	0.0003 (0.0091)	0.085 (0.051)	97.66 (98.23)
[468/469]	0.0049 (0.0120)	0.0029 (0.0091)	0.005 (0.050)	100.00 (98.26)
 * Train Acc 98.260
 * Val Acc 98.380, Total time 1.03
Epoch:2
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1301 (0.1301)	0.1266 (0.1266)	0.014 (0.014)	100.00 (100.00)
[100/469]	0.0038 (0.0137)	0.0014 (0.0104)	0.023 (0.034)	99.22 (98.82)
[200/469]	0.0115 (0.0126)	0.0090 (0.0096)	0.065 (0.036)	98.44 (98.76)
[300/469]	0.0046 (0.0122)	0.0021 (0.0093)	0.015 (0.036)	98.44 (98.70)
[400/469]	0.0052 (0.0120)	0.0031 (0.0092)	0.039 (0.038)	98.44 (98.65)
[468/469]	0.0056 (0.0121)	0.0034 (0.0093)	0.032 (0.038)	98.96 (98.66)
 * Train Acc 98.663
 * Val Acc 98.460, Total time 1.03
Epoch:3
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1454 (0.1454)	0.1418 (0.1418)	0.046 (0.046)	99.22 (99.22)
[100/469]	0.0025 (0.0129)	0.0003 (0.0103)	0.041 (0.027)	96.88 (98.96)
[200/469]	0.0029 (0.0123)	0.0003 (0.0096)	0.028 (0.027)	99.22 (99.01)
[300/469]	0.0045 (0.0124)	0.0021 (0.0097)	0.017 (0.027)	100.00 (99.00)
[400/469]	0.0025 (0.0122)	0.0003 (0.0094)	0.056 (0.028)	99.22 (98.99)
[468/469]	0.0210 (0.0121)	0.0189 (0.0094)	0.018 (0.029)	98.96 (98.97)
 * Train Acc 98.967
 * Val Acc 98.450, Total time 1.05
 * Val Acc 98.450, Total time 1.02
OrderedDict([('All', {'All': 98.45})])
Task All average acc: 98.45
===Summary of experiment repeats: 6 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [98.84 98.66 98.85 98.67 98.78 98.45  0.    0.    0.    0.  ]
mean: 59.225 std: 48.35712693078446
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
FF mlp
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=False)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=False)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (All): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model:  570402
no learnable params:  570402
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1043 (0.1043)	0.0988 (0.0988)	0.687 (0.687)	61.72 (61.72)
[100/469]	0.0025 (0.0125)	0.0004 (0.0100)	0.076 (0.197)	96.09 (91.82)
[200/469]	0.0027 (0.0119)	0.0003 (0.0093)	0.146 (0.147)	94.53 (94.12)
[300/469]	0.0315 (0.0119)	0.0270 (0.0093)	0.059 (0.126)	97.66 (95.03)
[400/469]	0.0079 (0.0120)	0.0037 (0.0091)	0.041 (0.113)	99.22 (95.62)
[468/469]	0.0202 (0.0119)	0.0181 (0.0090)	0.087 (0.106)	96.88 (95.90)
 * Train Acc 95.900
 * Val Acc 97.920, Total time 1.10
Epoch:1
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1452 (0.1452)	0.1416 (0.1416)	0.079 (0.079)	98.44 (98.44)
[100/469]	0.0245 (0.0129)	0.0222 (0.0103)	0.050 (0.055)	97.66 (97.98)
[200/469]	0.0102 (0.0121)	0.0078 (0.0096)	0.036 (0.052)	99.22 (98.08)
[300/469]	0.0223 (0.0119)	0.0198 (0.0093)	0.124 (0.052)	96.09 (98.11)
[400/469]	0.0025 (0.0120)	0.0003 (0.0091)	0.035 (0.052)	96.88 (98.14)
[468/469]	0.0025 (0.0119)	0.0002 (0.0091)	0.012 (0.050)	100.00 (98.23)
 * Train Acc 98.235
 * Val Acc 98.430, Total time 1.00
Epoch:2
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1390 (0.1390)	0.1355 (0.1355)	0.014 (0.014)	99.22 (99.22)
[100/469]	0.0027 (0.0129)	0.0003 (0.0104)	0.026 (0.034)	100.00 (98.70)
[200/469]	0.0039 (0.0121)	0.0016 (0.0096)	0.013 (0.035)	100.00 (98.75)
[300/469]	0.0026 (0.0120)	0.0003 (0.0094)	0.003 (0.035)	100.00 (98.72)
[400/469]	0.0025 (0.0121)	0.0003 (0.0094)	0.075 (0.036)	98.44 (98.71)
[468/469]	0.0136 (0.0120)	0.0110 (0.0094)	0.013 (0.036)	100.00 (98.72)
 * Train Acc 98.717
 * Val Acc 98.360, Total time 1.01
Epoch:3
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1502 (0.1502)	0.1463 (0.1463)	0.026 (0.026)	99.22 (99.22)
[100/469]	0.0199 (0.0129)	0.0172 (0.0103)	0.047 (0.030)	96.88 (98.97)
[200/469]	0.0036 (0.0122)	0.0014 (0.0095)	0.052 (0.028)	97.66 (99.06)
[300/469]	0.0024 (0.0123)	0.0003 (0.0093)	0.026 (0.028)	99.22 (99.03)
[400/469]	0.0166 (0.0121)	0.0143 (0.0092)	0.024 (0.028)	99.22 (99.03)
[468/469]	0.0022 (0.0120)	0.0002 (0.0091)	0.057 (0.028)	96.88 (99.01)
 * Train Acc 99.012
 * Val Acc 98.470, Total time 0.99
 * Val Acc 98.470, Total time 1.07
OrderedDict([('All', {'All': 98.47})])
Task All average acc: 98.47
===Summary of experiment repeats: 7 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [98.84 98.66 98.85 98.67 98.78 98.45 98.47  0.    0.    0.  ]
mean: 69.072 std: 45.21841722130486
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
FF mlp
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=False)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=False)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (All): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model:  570402
no learnable params:  570402
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1434 (0.1434)	0.1396 (0.1396)	0.725 (0.725)	44.53 (44.53)
[100/469]	0.0169 (0.0127)	0.0137 (0.0101)	0.201 (0.216)	92.97 (90.67)
[200/469]	0.0124 (0.0126)	0.0071 (0.0097)	0.116 (0.157)	92.97 (93.62)
[300/469]	0.0025 (0.0122)	0.0003 (0.0094)	0.054 (0.130)	98.44 (94.85)
[400/469]	0.0022 (0.0120)	0.0003 (0.0092)	0.165 (0.116)	95.31 (95.47)
[468/469]	0.0022 (0.0120)	0.0002 (0.0092)	0.043 (0.109)	98.96 (95.79)
 * Train Acc 95.787
 * Val Acc 97.520, Total time 1.02
Epoch:1
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1120 (0.1120)	0.1083 (0.1083)	0.065 (0.065)	97.66 (97.66)
[100/469]	0.0022 (0.0133)	0.0003 (0.0105)	0.048 (0.049)	97.66 (98.36)
[200/469]	0.0045 (0.0125)	0.0003 (0.0099)	0.096 (0.050)	96.09 (98.30)
[300/469]	0.0042 (0.0123)	0.0003 (0.0095)	0.053 (0.050)	98.44 (98.32)
[400/469]	0.0026 (0.0122)	0.0003 (0.0094)	0.107 (0.050)	96.09 (98.31)
[468/469]	0.0019 (0.0121)	0.0001 (0.0094)	0.015 (0.049)	100.00 (98.35)
 * Train Acc 98.348
 * Val Acc 98.570, Total time 0.98
Epoch:2
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1443 (0.1443)	0.1407 (0.1407)	0.021 (0.021)	99.22 (99.22)
[100/469]	0.0094 (0.0128)	0.0071 (0.0103)	0.042 (0.036)	98.44 (98.82)
[200/469]	0.0060 (0.0127)	0.0003 (0.0100)	0.063 (0.037)	96.09 (98.73)
[300/469]	0.0085 (0.0123)	0.0047 (0.0096)	0.019 (0.037)	99.22 (98.74)
[400/469]	0.0030 (0.0123)	0.0003 (0.0096)	0.012 (0.037)	99.22 (98.71)
[468/469]	0.0020 (0.0122)	0.0002 (0.0095)	0.026 (0.038)	97.92 (98.69)
 * Train Acc 98.687
 * Val Acc 98.540, Total time 1.00
Epoch:3
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1162 (0.1162)	0.1128 (0.1128)	0.016 (0.016)	100.00 (100.00)
[100/469]	0.0252 (0.0127)	0.0226 (0.0101)	0.099 (0.031)	98.44 (98.88)
[200/469]	0.0026 (0.0120)	0.0004 (0.0095)	0.009 (0.031)	100.00 (98.85)
[300/469]	0.0028 (0.0119)	0.0004 (0.0093)	0.008 (0.031)	100.00 (98.88)
[400/469]	0.0205 (0.0119)	0.0175 (0.0093)	0.016 (0.031)	99.22 (98.87)
[468/469]	0.0053 (0.0118)	0.0034 (0.0091)	0.021 (0.031)	97.92 (98.88)
 * Train Acc 98.880
 * Val Acc 98.690, Total time 1.06
 * Val Acc 98.690, Total time 1.07
OrderedDict([('All', {'All': 98.69})])
Task All average acc: 98.69
===Summary of experiment repeats: 8 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [98.84 98.66 98.85 98.67 98.78 98.45 98.47 98.69  0.    0.  ]
mean: 78.941 std: 39.470705200186124
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
FF mlp
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=False)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=False)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (All): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model:  570402
no learnable params:  570402
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1476 (0.1476)	0.1435 (0.1435)	0.684 (0.684)	63.28 (63.28)
[100/469]	0.0024 (0.0127)	0.0003 (0.0102)	0.082 (0.200)	98.44 (91.97)
[200/469]	0.0032 (0.0125)	0.0005 (0.0094)	0.055 (0.148)	97.66 (94.24)
[300/469]	0.0200 (0.0122)	0.0177 (0.0092)	0.066 (0.128)	96.88 (95.13)
[400/469]	0.0274 (0.0121)	0.0248 (0.0091)	0.034 (0.113)	98.44 (95.73)
[468/469]	0.0019 (0.0119)	0.0001 (0.0090)	0.015 (0.105)	100.00 (96.03)
 * Train Acc 96.032
 * Val Acc 98.140, Total time 1.00
Epoch:1
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1270 (0.1270)	0.1192 (0.1192)	0.033 (0.033)	98.44 (98.44)
[100/469]	0.0041 (0.0135)	0.0019 (0.0108)	0.042 (0.048)	98.44 (98.22)
[200/469]	0.0028 (0.0125)	0.0003 (0.0099)	0.071 (0.052)	96.88 (98.14)
[300/469]	0.0024 (0.0122)	0.0003 (0.0096)	0.013 (0.051)	100.00 (98.18)
[400/469]	0.0299 (0.0121)	0.0277 (0.0095)	0.029 (0.051)	98.44 (98.19)
[468/469]	0.0022 (0.0119)	0.0001 (0.0093)	0.045 (0.050)	98.96 (98.23)
 * Train Acc 98.228
 * Val Acc 98.380, Total time 1.00
Epoch:2
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1106 (0.1106)	0.1005 (0.1005)	0.048 (0.048)	98.44 (98.44)
[100/469]	0.0023 (0.0137)	0.0003 (0.0110)	0.054 (0.032)	96.88 (98.79)
[200/469]	0.0280 (0.0127)	0.0259 (0.0101)	0.014 (0.035)	100.00 (98.76)
[300/469]	0.0024 (0.0123)	0.0003 (0.0097)	0.005 (0.036)	100.00 (98.76)
[400/469]	0.0086 (0.0123)	0.0063 (0.0097)	0.054 (0.037)	96.88 (98.73)
[468/469]	0.0119 (0.0123)	0.0059 (0.0096)	0.080 (0.037)	96.88 (98.70)
 * Train Acc 98.702
 * Val Acc 98.440, Total time 1.09
Epoch:3
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1449 (0.1449)	0.1415 (0.1415)	0.010 (0.010)	99.22 (99.22)
[100/469]	0.0035 (0.0128)	0.0014 (0.0104)	0.005 (0.026)	100.00 (99.04)
[200/469]	0.0028 (0.0121)	0.0003 (0.0096)	0.074 (0.027)	98.44 (99.04)
[300/469]	0.0024 (0.0121)	0.0003 (0.0094)	0.047 (0.027)	97.66 (99.02)
[400/469]	0.0043 (0.0119)	0.0005 (0.0093)	0.019 (0.027)	99.22 (99.05)
[468/469]	0.0020 (0.0120)	0.0001 (0.0093)	0.005 (0.027)	100.00 (99.03)
 * Train Acc 99.035
 * Val Acc 98.820, Total time 1.03
 * Val Acc 98.820, Total time 1.03
OrderedDict([('All', {'All': 98.82})])
Task All average acc: 98.82
===Summary of experiment repeats: 9 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [98.84 98.66 98.85 98.67 98.78 98.45 98.47 98.69 98.82  0.  ]
mean: 88.82300000000001 std: 29.607971240866874
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
FF mlp
MLP(
  (linear): Sequential(
    (0): Linear(in_features=1024, out_features=400, bias=False)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=400, out_features=400, bias=False)
    (3): ReLU(inplace=True)
  )
  (last): ModuleDict(
    (All): Linear(in_features=400, out_features=2, bias=True)
  )
)
#parameter of model:  570402
no learnable params:  570402
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1118 (0.1118)	0.1081 (0.1081)	0.691 (0.691)	48.44 (48.44)
[100/469]	0.0275 (0.0136)	0.0251 (0.0107)	0.138 (0.198)	95.31 (91.92)
[200/469]	0.0090 (0.0125)	0.0066 (0.0099)	0.063 (0.149)	97.66 (94.10)
[300/469]	0.0027 (0.0121)	0.0003 (0.0094)	0.039 (0.126)	99.22 (95.09)
[400/469]	0.0138 (0.0122)	0.0065 (0.0092)	0.115 (0.112)	97.66 (95.74)
[468/469]	0.0026 (0.0121)	0.0002 (0.0091)	0.158 (0.105)	95.83 (96.02)
 * Train Acc 96.017
 * Val Acc 97.890, Total time 1.02
Epoch:1
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1237 (0.1237)	0.1168 (0.1168)	0.070 (0.070)	97.66 (97.66)
[100/469]	0.0025 (0.0127)	0.0003 (0.0102)	0.036 (0.054)	98.44 (98.13)
[200/469]	0.0195 (0.0125)	0.0173 (0.0098)	0.047 (0.055)	98.44 (98.08)
[300/469]	0.0217 (0.0122)	0.0194 (0.0095)	0.024 (0.055)	100.00 (98.10)
[400/469]	0.0134 (0.0120)	0.0109 (0.0093)	0.067 (0.053)	98.44 (98.16)
[468/469]	0.0122 (0.0119)	0.0098 (0.0093)	0.025 (0.052)	100.00 (98.20)
 * Train Acc 98.205
 * Val Acc 98.440, Total time 1.07
Epoch:2
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1333 (0.1333)	0.1301 (0.1301)	0.017 (0.017)	99.22 (99.22)
[100/469]	0.0159 (0.0129)	0.0137 (0.0104)	0.016 (0.037)	99.22 (98.69)
[200/469]	0.0285 (0.0122)	0.0261 (0.0097)	0.028 (0.035)	97.66 (98.73)
[300/469]	0.0025 (0.0122)	0.0003 (0.0095)	0.017 (0.036)	99.22 (98.75)
[400/469]	0.0025 (0.0120)	0.0003 (0.0093)	0.057 (0.035)	99.22 (98.78)
[468/469]	0.0207 (0.0120)	0.0186 (0.0093)	0.013 (0.036)	98.96 (98.75)
 * Train Acc 98.747
 * Val Acc 98.540, Total time 1.01
Epoch:3
LR: 0.001
Itr		Time		  Data		  Loss		Acc
[0/469]	0.1425 (0.1425)	0.1363 (0.1363)	0.009 (0.009)	100.00 (100.00)
[100/469]	0.0080 (0.0138)	0.0046 (0.0102)	0.040 (0.027)	99.22 (98.99)
[200/469]	0.0033 (0.0127)	0.0003 (0.0096)	0.093 (0.027)	98.44 (99.01)
[300/469]	0.0216 (0.0122)	0.0187 (0.0091)	0.010 (0.028)	100.00 (99.00)
[400/469]	0.0040 (0.0121)	0.0016 (0.0091)	0.003 (0.029)	100.00 (98.94)
[468/469]	0.0018 (0.0119)	0.0001 (0.0090)	0.106 (0.030)	98.96 (98.94)
 * Train Acc 98.940
 * Val Acc 98.470, Total time 0.93
 * Val Acc 98.470, Total time 0.89
OrderedDict([('All', {'All': 98.47})])
Task All average acc: 98.47
===Summary of experiment repeats: 10 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [98.84 98.66 98.85 98.67 98.78 98.45 98.47 98.69 98.82 98.47]
mean: 98.67 std: 0.14993331851192948
reg_coef: 0.0 mean: 98.67 std: 0.14993331851192948
